hello world	你好世界
good morning	早上好
goodbye friend	再见朋友
see you	再见
take care	小心
welcome back	欢迎回来
how are you	你好吗
our world	我们的世界
our sky	我们的天空
smile sky	微笑的天空
can you speak english	你能说英语吗
thank you	谢谢你
the weather is nice today	今天天气很好
i like eating apples	我喜欢吃苹果
what's your name	你叫什么名字
what time is it now	现在几点了
this is my book	这是我的书
let's go to the park	我们去公园吧
i live in beijing	我住在北京
see you tomorrow	明天见
how much is this	这个多少钱
i'm a little tired	我有点累了
please help me	请帮我一下
where are you from	你来自哪里
have a nice weekend	周末愉快
i understand	我明白了
thank for your help	谢谢你的帮助
happy birthday to you	祝你生日快乐
i don't agree	我不同意
this is a good idea	这是个好主意
he is learning chinese	他在学习中文
invalid syntax	无效的语法
name is not defined	名称未定义
list index out of range	列表索引超出范围
expected an indented block	需要一个缩进的代码块
no such file or directory	没有这样的文件或目录
maximum call stack size exceeded	超出最大调用堆栈大小
uri malformed	URI格式不正确
too much recursion	递归过深
invalid argument	无效的参数
file not found	文件未找到
segmentation fault	段错误
out of memory	内存不足
stack overflow	堆栈溢出
division by zero	除以零错误
timeout expired	超时已过期
permission denied	权限被拒绝
connection refused	连接被拒绝
resource temporarily unavailable	资源暂时不可用
operation not permitted	操作不被允许
error count exceeds number	错误太多
unexpected end of file found	意外的文件结束
cannot open include file	无法打开头文件
newline in constant	常量中有换行符
undeclared identifier	未声明的标识符
syntax error	语法错误
identifier not found	找不到标识符
must return a value	必须返回一个值
this function or variable may be unsafe	此函数或变量可能不安全
pure virtual method called	调用了纯虚函数
double free or corruption	双重释放或内存损坏
memory corruption	内存损坏
stack smashing detected	检测到堆栈破坏
floating point exception	浮点异常
microsoft visual c++ runtime library runtime error	微软Visual C++运行时库运行时错误
vector subscript out of range	向量下标越界
undefined symbol in function	函数中未定义的符号
ambiguous operators need parentheses	不明确的运算需要用括号括起
array bounds missing	丢失数组界限符
array size too large	数组尺寸太大
bad character in parameters	参数中有不适当的字符
call of non-function	调用非函数
cannot modify a const object	不能修改常量对象
go home	回家
privacy policy	隐私政策
data access	数据访问
usage policy	使用政策
report a bug	报告一个错误
system status	系统状态
get help	获取帮助
rust foundation	Rust基金会
latest updates	最近更新
show all	显示全部
change color scheme	更改配色方案
getting started	入门
install cargo	安装Cargo
most downloaded	下载次数最多
just updated	刚刚更新
most recent downloads	最近下载
popular keywords	流行的关键词
popular categories	热门分类
run the following cargo command in your project directory	在项目目录中运行以下Cargo命令
stats overview	统计数据概览
build it in rust	使用Rust构建
command line	命令行
contribute code	贡献代码
corporate sponsors	企业赞助商
see foundation members	查看基金会成员
ask a question on the users forum	在用户论坛上提问
terms and policies	条款和政策
code of conduct	行为守则
logo policy and media guide	徽标政策和媒体指南
security disclosures	安全披露
privacy notice	隐私声明
all policies	所有政策
other changes	其他变化
get in-depth tutorials for beginners and advanced developers	获取针对初学者和高级开发人员的深入教程
view tutorials	查看教程
find development resources and get your questions answered	查找开发资源并解答您的问题
view resources	查看资源
first name	名字
last name	姓氏
technical advisory council	技术咨询委员会
cloud credit program	云信用计划
run this command	运行此命令
quick start with cloud partners	与云合作伙伴快速入门
google cloud platform	谷歌云平台
browse projects	浏览项目
featured projects	特色项目
read case studies	阅读案例研究
pushing the state of the art in nlp and multi-task learning	推动NLP和多任务学习的最新技术
stanford university	斯坦福大学
view docs	查看文档
skip to content	跳到内容
navigation menu	导航菜单
open global navigation menu	打开全局导航菜单
search or jump to	搜索或跳至
you have no unread notifications	您没有未读的通知
open user navigation menu	打开用户导航菜单
suggest next steps for an issue	针对问题提出后续步骤建议
show more	显示更多
recent activity	近期活动
read more	阅读更多
see more	查看更多
popular projects among people you follow	您关注的人中的流行项目
add this repository to a list	将此存储库添加到列表
new feature	新功能
support table topic to seamless ingest kafka records to iceberg table	支持表主题无缝提取Kafka记录到Iceberg表
support deploy on kubernetes	支持在Kubernetes上部署
what's c	什么是C
what's changed	发生了什么变化
last week	上周
fallback tauri version to fix image loading failure issue	回退Tauri版本以修复图像加载失败问题
improve image file preview style	改进图像文件预览样式
zig library for reading and writing different image formats	用于读取和写入不同图像格式的Zig库
footer navigation	页脚导航
manage cookies	管理Cookie
do not share my personal information	不要分享我的个人信息
easy to use talking installer	易于使用的语音安装程序
announcing controls and text while using touch gestures	使用触摸手势时宣布控件和文本
support for windows command prompt and console applications	支持Windows命令提示符和控制台应用程序
security fixes	安全修复
new features	新功能
changes to the com registration fixing tool	更改COM注册修复工具
bug fixes	错误修复
certain section elements are now correctly recognized as editable controls in visual studio code	某些部分元素现在被正确识别为VSC中的可编辑控件
proper support for phi-4	对Phi4的适当支持
add phi-4 support	添加Phi4支持
fix docs quantized qwen3	修复文档量化Qwen3
update olmo-2 to example	将Olmo2更新为示例
clippy fix	Clippy修复
optimize kv cache to reduce gpu memory usage	优化KV缓存以减少GPU内存使用率
add resize to onnx ops	将调整大小添加到ONNX OPS
cleanup and added other unused options for this op	清理并添加了此OP的其他未使用的选项
fixed image loading to make output work	修复图像加载以使输出工作
cleanup and removed unused variables	清理和删除未使用的变量
qwen3 quantized implementation	Qwen3量化的实现
clippy fixes	Clippy修复
add some testing	添加一些测试
another test	另一个测试
fixed compile error	修复编译错误
different qwen variants working	不同的Qwen变体正在工作
added moe model	添加了MOE模型
added additional eos token	添加了额外的EOS令牌
translated korean comments to english as well as i can	将韩语注释翻译为英语
running the example	运行示例
cast the audio data to the correct sampling rate for the model	将音频数据转换为适合模型的正确采样率
pre-process the inputs	预处理输入
explicitly encode then decode the audio inputs	明确编码然后解码音频输入
or the equivalent with a forward pass	或等效的前向传播
follow kyutai	关注Kyutai
feature extraction	特征提取
model card	模型卡
use this model	使用此模型
edit model card	编辑模型卡
model card for mimi	Mimi的模型卡
model details	模型详细信息
model description	模型描述
model sources	模型源代码
how to get started with the model	如何开始使用模型
usage with transformers	与Transformer一起使用
load a demonstration datasets	加载演示数据集
usage with moshi	与Moshi一起使用
see the main readme file	查看主要的说明文件
direct use	直接使用
the model is not intended to be used to impersonate other people or any malicious use of any kind	该模型不可用于冒充他人或任何形式的恶意使用
training details	训练详情
training data	训练数据
the training data is detailled in the paper	训练数据详见论文
training procedure and hyper-parameters	训练过程和超参数
the different stages of the training procedure are detailled in the paper along with the hyper-parameters	论文详细介绍了训练过程的不同阶段以及超参数
model card authors	模型卡作者
downloads last month	上个月下载
model size	模型大小
tensor type	张量类型
files info	文件信息
inference providers	推理提供者
select the account to bill	选择帐户账单
hf inference api	HF推理API
your sentence here	在这里输入你的句子
view code	查看代码
spaces using	空间使用
system theme	系统主题
repositories search results	存储库搜索结果
filter by type	按类型筛选
your search did not match any repositories	您的搜索未匹配到任何仓库
alternatively try one of the tips below	或者尝试以下小提示之一
search across an organization	跨组织搜索
saved searches	保存的搜索
you could try an advanced search	您可以尝试高级搜索
repository search results	存储库搜索结果
explore sponsorable projects	探索赞助项目
how can we improve search	我们如何改进搜索
supporting two stream models	支持两种流模型
revert debug change	恢复调试更改
revert debug value	还原调试值
missing revert	缺少恢复
new import script	新的导入脚本
adding empty mimi possibility	增加空的Mimi可能性
adding reset support	添加重置支持
no comment	没有注释
fixing bug with weight shared import in rust	修复Rust中权重共享导入的错误
more stuff i need	我需要的更多东西
remove dbg	移除DBG
doc and new fields	文档和新的字段
initial implem for missing data support	初始实施缺少数据支持
removing torch compile and fixes	删除torch编译并修复
prefix dict has been built successfully	前缀字典已成功构建
rust based mimi with python bindings	基于Rust的Mimi与Python绑定
install from pip	从pip安装
if you want to compile the package run from the root of the repo	如果要编译包，请从仓库的根目录运行
rust server	Rust服务端
rust command line	Rust命令行
the present code is provided under the apache license	本代码是在Apache许可证下提供的
the connection takes place using a websocket	连接使用WebSocket进行
this handles the message lengths for us	这为我们处理消息长度
the binary protocol for messages is as follows	消息的二进制协议如下
the protocol uses little endian encoding	该协议使用小端序字节编码
each message starts by a single byte indicating the message type `MT`	每条消息以一个字节开头，表示消息类型“MT”
the format for the rest of the message, aka the payload, depends on `MT`	其余消息的格式（又称有效载荷）取决于“MT”
the payload is made of two fields	有效载荷由两个字段组成
the payload is made of a single field	有效载荷由单个字段组成
utf8 encoded string	UTF8编码的字符串
this is not used in full streaming mode	这在整个流模式下不使用
i'm glad	我很高兴
one byte b describing the control itself	一个字节B描述控制本身
utf8 encoded string with json data	带JSON数据的UTF8编码的字符串
utf8 encoded string containing the error description	包含错误描述的UTF8编码的字符串
no payload, this message type is currently unused	无有效负载，此消息类型当前未使用
messages with an unknown message types should be discarded	应丢弃消息类型未知的消息
moshi is a speech-text foundation model and full-duplex spoken dialogue framework	Moshi是一个语音文本基础模型和全双工口语对话框架
it uses mimi, a state-of-the-art streaming neural audio codec	它使用Mimi——一种最先进的流神经音频编解码器
this is the pytorch implementation for moshi and mimi	这是Moshi和Mimi的PyTorch实现
while we hope that the present codebase will work on windows, we do not provide official support for it	虽然我们希望当前的代码库能在Windows上使用，但我们不为此提供官方支持
this package provides a streaming version of the audio tokenizer (mimi) and the lm model (moshi)	此软件包提供了音频标记器（Mimi）和LM模型（Moshi）的流式版本
in order to run in interactive mode, you need to start a server which will run the model, you can then use either the web ui or a command line client	为了以交互模式运行，您需要启动一个运行模型的服务端，然后您可以使用Web UI或命令行客户端
alternatively, you might want to use ssh to redirect your connection	另外，您可能需要使用SSH重定向连接
however note, that unlike the web browser, this client is barebone	但是请注意，与Web浏览器不同，此客户端是基本的
it does not perform any echo cancellation, nor does it try to compensate for a growing lag by skipping frames	它不执行任何回声消除，也不试图通过跳过帧来补偿不断增长的延迟
you can use programmatically the mimi/moshi as follows	您可以按以下方式编程使用Mimi/Moshi
supports streaming too	也支持流式
now if you have a gpu around	现在，如果你周围有GPU
now we will stream over both moshi i/o, and decode on the fly with mimi	现在，我们将通过Moshi I/O进行流式传输，并使用Mimi进行实时解码
streaming execution mask	流执行掩码
it is possible to run on desynchronized batches, e.g. batch for which not all items are coming in at the same rate	可以在不同步的批次上运行，例如，并非所有项目都以相同的速率进入的批次
from the point of view of the first and third entries, nothing has happen	从第一个和第三个条目的角度来看，什么都没有发生
the codes for those two should simply be discarded	这两个的代码应该简单地丢弃
if you wish to install from a clone of this repository, maybe to further develop moshi, you can do the following	如果您想从此存储库的克隆中安装，也许要进一步开发Moshi，您可以执行以下操作
from the current folder (e.g. `moshi/`)	从当前文件夹（例如`moshi/`）
the present code is provided under the mit license	本代码根据MIT许可证提供
if you use either mimi or moshi, please cite the following paper	如果您使用Mimi或Moshi，请引用以下论文
how was your day today	你今天过得怎么样
i watched a great movie yesterday	我昨天看了一部很棒的电影
could you help me with that bag	你能帮我拿一下那个包吗
the food at this restaurant is really delicious	这家餐厅的菜真的很美味
i prefer tea to coffee	我更喜欢喝茶而不是咖啡
deep learning is a subfield of machine learning	深度学习是机器学习的一个子领域
quantum computers use qubits for computation	量子计算机利用量子比特进行计算
blockchain technology provides decentralized solutions	区块链技术提供了去中心化的解决方案
neural networks consist of multiple interconnected layers	神经网络由多个相互连接的层组成
nlp enables computers to understand human language	自然语言处理使计算机能理解人类语言
spring festival is the most important traditional holiday in china	春节是中国最重要的传统节日
the eiffel tower is an iconic landmark in paris	埃菲尔铁塔是巴黎的地标性建筑
in france, it's common to place bread directly on the table during meals	在法国，用餐时把面包直接放在桌上是常见的
japanese tea ceremony embodies the spirit of "harmony, respect, purity and tranquility"	日本茶道体现了“和敬清寂”的精神
italians are known for their hospitality	意大利人以热情好客著称
please find attached the project proposal as requested	随函附上您要求的项目提案
the board meeting will be held next wednesday at 3pm	董事会将于下周三下午三点召开
we are honored to invite you to this seminar	我们很荣幸邀请您参加本次研讨会
this contract shall take effect from the date of signing by both parties	本合同自双方签字之日起生效
should you have any questions about this product, please feel free to contact customer service	如对本产品有任何疑问，请随时联系客服
although it was raining, they decided to continue the hike	尽管下雨了，他们还是决定继续徒步旅行
this book is not only rich in content but also beautifully bound	这本书不仅内容丰富，而且装帧精美
the earlier you submit the application, the greater the chance of approval	你越早提交申请，获得批准的机会就越大
it is reported that this new drug is highly effective in treating the disease	据报道，这种新药对治疗该疾病非常有效
all factors considered, this solution is the most feasible	考虑到所有因素，这个方案是最可行的
try it now	立即试用
discover the technology	发现技术
slowly and not without struggle, america began to listen	美国缓慢地开始倾听，但并非没有艰难曲折
some of these may have been generated by your ide	这其中的一些文件可能已经由IDE生成
dithering is a technique that blends your colors together, making them look smoother, or just creating interesting textures	抖动是关于颜色混合的技术，使你的作品看起来更圆滑，或者只是创作有趣的材质
the second encounter relates to my grandfather's treasure box	第二次邂逅与我祖父的宝箱有关
when you eat dinner out, reduce the temptation to clean your plate by setting aside one-third of your meal	当你在外吃晚餐的时候，把你晚餐中三分之一的食物放置在一边
sang lan is one of the best athletes in our country	桑兰是我国最好的运动员之一
miaoxiang son know the devil tricks, white three quick deployment	苗香儿知道了鬼子的诡计，白三部署速战速结
further development of the central cell mainly involved changes in the orientation of the polar nuclei and the distribution of the cytoplasm	中央细胞的后续发育主要表现为极核排列方向的变化及细胞质分布的动态调整
the first parameter to the script is saved to a variable called $ip	脚本的第一个参数被保存为一个名为$IP的变量
she just gaped at me when i told her the news	我告诉她这个消息时，她简直目瞪口呆
they walked in a stooped posture, the shoulders well forward, the head still farther forward, the eyes bent upon the ground	他们弯腰前行，肩膀前倾，脑袋更加前倾，眼睛专注地盯着地面
i like blue skies and white clouds	我喜欢蓝天白云
an error happened while trying to locate the file on the hub and we cannot find the requested files in the local cache	尝试在Hub上查找文件时出错，我们在本地缓存中找不到请求的文件
please check your connection and try again or make sure your internet connection is on	请检查您的连接并重试，或确保您的互联网连接已打开
cannot find a working triton installation	找不到可用的Triton安装
either the package is not installed or it is too old	该软件包未安装或太旧
no packages published	未发布任何包
development repository for the triton language and compiler	Triton语言和编译器的开发仓库
public repository	公共存储库
main branch	主分支
open more actions menu	打开更多操作菜单
folders and files	文件夹和文件
last commit date	最后提交日期
latest commit	最新提交
open commit details	打开提交详细信息
view all files	查看所有文件
repository files navigation	存储库文件导航
edit file	编辑文件
triton logo	Triton标志
this is the development repository of triton, a language and compiler for writing highly efficient custom deep-learning primitives	这是Triton的开发仓库，Triton是一种用于编写高效自定义深度学习原语的语言和编译器
the aim of triton is to provide an open-source environment to write fast code at higher productivity than cuda, but also with higher flexibility than other existing dsls	Triton的目标是提供一个开源环境，以比CUDA更高的生产力编写快速代码，同时比其他现有DSL具有更高的灵活性
an intermediate language and compiler for tiled neural network computations	分层神经网络计算的中间语言和编译器
please consider citing this work if you use triton	如果您使用Triton，请考虑引用这项工作
the official documentation contains installation instructions and tutorials	官方文档包含安装说明和教程
see also these third-party triton puzzles, which can all be run using the triton interpreter -- no gpu required	另请参阅这些第三方Triton示例程序，它们均可通过Triton解释器运行——无需GPU支持
quick installation	快速安装
you can install the latest stable release of triton from pip	您可以从pip安装Triton的最新稳定发行版
install from source	从源代码安装
or with a virtualenv	或者使用虚拟环境
building with a custom llvm	用自定义LLVM构建
triton uses llvm to generate code for gpus and cpus	Triton使用LLVM为GPU和CPU生成代码
normally, the triton build downloads a prebuilt llvm, but you can also build llvm from source and use that	通常，Triton构建会下载预构建的LLVM，但您也可以从源代码构建LLVM并使用
llvm does not have a stable api, so the triton build will not work at an arbitrary llvm version	LLVM没有稳定的API，因此Triton构建无法在任意LLVM版本上工作
find the version of llvm that triton builds against	查找Triton构建的LLVM版本
check to see the current version	检查以查看当前版本
for example, if it says	例如，如果它说
this means that the version of triton you have builds against llvm	这意味着您当前使用的Triton版本是基于LLVM构建的
git checkout llvm at this revision	使用Git将LLVM检出至该修订版本
optionally, make additional modifications to llvm	（可选）对LLVM进行其他修改
build llvm	构建LLVM
grab a snack, this will take a while	吃点零食，这需要一段时间
build triton as above, but set the following environment variables	如上所述构建Triton，但需设置以下环境变量
modify as appropriate to point to your llvm build	根据需要进行修改，以指向您的LLVM构建
tips for building	构建小提示
set as an environment variable to use clang and lld	设置为环境变量以使用clang和lld
lld in particular results in faster builds	lld尤其能加快构建速度
set to change the location of the directory where triton's cache is located and downloads are stored during the build	用于设置Triton构建过程中缓存目录和下载存储目录的位置
by default, this is the user's home directory	默认情况下，这是用户的主目录
it can be changed anytime	可以随时更改
if you're running out of memory when building triton, specify the environment variable to limit the number of jobs	如果在构建Triton时内存不足，请指定环境变量以限制作业数量
running tests	运行测试
there currently isn't a turnkey way to run all the triton tests, but you can follow the following recipe	目前尚无开箱即用的方法可一键运行所有Triton测试，但您可以按以下步骤操作
one-time setup	一次性设置
note this will reinstall local triton because torch	请注意，由于PyTorch的原因这将重新安装本地Triton
overwrites it with the public version	用公共版本覆盖它
to run all tests (requires a gpu)	运行所有测试（需要GPU）
or, to run tests without a gpu	或者，在没有GPU的情况下运行测试
tips for hacking	黑客技巧
for detailed instructions on how to debug triton's frontend, please refer to this tutorial	有关如何调试Triton的前端的详细说明，请参阅本教程
the following includes additional tips for hacking on triton's backend	以下包含针对Triton后端进行深度开发的额外实用技巧
configuration knobs	配置旋钮
you can set those knobs directly in python or use environment variables to control them	您可以直接在Python中设置这些旋钮，也可以使用环境变量来控制它们
triton cache can interfere with the dump	Triton缓存可能会干扰转储
when enabling the address sanitizer it is recommended to disable various memory caching strategies both within the rocm stack and pytorch	启用地址清理程序时，建议禁用ROCm堆栈和PyTorch中的各种内存缓存策略
this will give the address sanitizer the best chance at finding the memory fault where it originates	这将使地址清理程序有最好的机会找到内存故障的根源
see this test for more details	有关更多详细信息，请参阅此测试
this can provide a direct mapping from the ir to llir/ptx	这可以提供从IR到llir/ptx的直接映射
when used with performance tools, it can provide a breakdown on ir instructions	结合性能工具使用时，能对IR指令进行细粒度分析
otherwise, it will be parsed as a list of flags to disable llvm optimizations	否则，它将被解析为禁用LLVM优化的标志列表
warnings, remarks, stacktraces, operations	警告，备注，堆栈，操作
use comma-separated values to customize output	使用逗号分隔值自定义输出
by default, only errors are shown	默认情况下，只显示错误
setting warnings includes errors and warnings	设置警告包括错误和警告
remarks includes errors, warnings, and remarks	备注包括错误、警告和备注
those are only relevant to the c++ layer(s), hence they don't exist in the python layer	这些只与C++层相关，因此它们不存在于Python层中
kernel override steps	内核覆盖步骤
delete the stages that you do not want to override and modify the stage you do want to override	删除不想覆盖的阶段，并修改要覆盖的阶段
run the kernel again to see the overridden result	再次运行内核以查看覆盖的结果
many, many bug fixes	许多错误修复
performance improvements	性能改进
backend rewritten to use mlir	后端重写以使用MLIR
support for kernels that contain back-to-back matmuls (e.g., flash attention)	支持包含连续矩阵乘法（如Flash Attention）的计算内核
community contributions are more than welcome, whether it be to fix bugs or to add new features at github	我们诚挚欢迎社区贡献，无论是修复漏洞还是为GitHub仓库添加新功能
for more detailed instructions, please visit our contributor's guide	有关更详细的说明，请访问我们的贡献者指南
supported platforms	支持的平台
supported hardware	支持的硬件
development container (dev container)	开发容器（Dev Container）
dev containers for the triton project are available from the triton-dev-containers repository	Triton项目的Dev Containers可从triton-dev-containers存储库获取
key benefits	关键优势
all developers can work with the same development environment, ensuring uniform behavior across different systems	所有开发人员都可以使用相同的开发环境，确保不同系统之间的行为一致
the container prevents potential conflicts with software installed on your local machine	容器可防止与本地计算机上安装的软件发生潜在冲突
easily share the development environment with team members, minimizing onboarding time and setup issues	轻松与团队成员共享开发环境，最大限度地减少入职时间和设置问题
how to use the dev container	如何使用开发容器
for detailed instructions on how to use the dev containers please see the dev container user guide	有关如何使用开发容器的详细说明，请参阅开发容器用户指南
if you have a bug or an idea, read the contributing guidelines before opening an issue	如果你发现了一个Bug或有一个想法，请在打开问题之前阅读贡献指南
new issue	创建新问题
search results	搜索结果
filter by author	按作者筛选
filter by label	按标签筛选
more actions	更多操作
not planned (skipped)	未计划（跳过）
closed (abandoned)	已关闭（废弃）
changes requested	请求更改
add python abi tag to the filename of cached c binary	将Python ABI标签添加到缓存的C二进制文件的文件名中
merged (completed)	已合并（完成）
when can cu128 be supported	什么时候可以支持CU128
closed (completed)	已关闭（完成）
steady error when using triton to do floating-point arithmetic	使用Triton进行浮点运算时的稳态误差
python stable abi in jit cache	JIT缓存中Python稳定的ABI
see all checks	查看所有检查
use env builtin implementation from llvm's lit utility for platform independence	使用LLVM的lit实用程序中的env内置实现，实现平台独立性
not able to install dependencies file	无法安装依赖项文件
pull requests that update a dependency file	更新依赖文件的拉取请求
python int too large to convert to c long	Python int 太大而无法转换为 C long
update cmake files with windows related changes	使用与Windows相关的更改来更新CMake文件
build smaller llvm binaries for triton	为Triton构建较小的LLVM二进制文件
next page	下一页
copy link	复制链接
issue body actions	问题主体操作
you've been using triton on windows iirc	您一直在Windows IIRC上使用Triton
what's your progress on it	你的进展如何
the current status is that we can build the code and successfully pass most of the unit tests on intel gpu	目前的状态是，我们可以在英特尔GPU上构建代码并成功通过大多数单元测试
you've written most of the details	大部分细节都是你写的
the code should build on windows but i had no opportunity to run it on nvidia gpu so i cannot say whether it works or not	代码应该在Windows上构建，但我没有机会在Nvidia GPU上运行它，所以我不能说它是否有效
however, this was previously noted to time out on macos frequently (because macos scans newly built executables for viruses, or something...) but the timeout argument was incorrectly specified	然而，之前已经注意到这在MacOS上经常超时（因为MacOS会扫描新构建的可执行文件中的病毒或其他东西……），不过超时参数的指定不正确
by setting a reproducer path, the pass manager will dump a standard mlir reproducer before each pass manager invocation	通过设置再现文件路径，传递管理器将在每次调用前转储标准的MLIR再现文件
this pr also enables additional local crash reproducer generation (to the same path set through the env var), which tries to narrow down the specific pass that failed, if the pass pipeline fails at any point	本次拉取请求（PR）还启用了额外的本地崩溃再现文件生成功能（保存至通过环境变量设置的同一路径），当传递流水线在任何环节失败时，该功能将尝试定位导致失败的具体传递
really both of these should be nvidia-specific but the first is exposed in the triton ir to keep support for the by-value tma descriptor api around while we figure out if it's possible to update to the new style	实际上这两者本应都是Nvidia专用的，但第一个功能被保留在Triton中间表示（IR）中以继续支持按值传递的TMA描述符API，同时我们正在评估是否可能迁移到新式设计
i hope this implementation will suit triton, or maybe one can suggest other options	我希望这种实现方式适合Triton，或者可以提出其他选择
this requires the following changes	这需要进行以下更改
please advise on the merging strategy	请就合并策略提出建议
i noticed this rather obvious pattern was missing	我注意到这个相当明显的模式不见了
it might come up for example if you have an expression like	例如，如果你有一个表达式，它可能会出现
fix incorrect mask operand used in for loop pipeliner	修复for循环流水线中使用的掩码操作数不正确的问题
however, if the load memory requires a layout change, the wrong mask operand was being passed to the `arith.select`, causing a shape mismatch	但是，如果加载内存需要更改布局，则传递给“arith.select”的掩码操作数错误，导致形状不匹配
cleanup redundant broadcast combine pattern	清理冗余广播组合模式
summary of changes	变更摘要
reorder the triton-combine pass to come after the canonicalize pass, to simplify pattern matching	将Triton组合过程重新排序到规范化过程之后，以简化模式匹配
it was duplicated due to resolving merge conflicts	由于解决合并冲突，它被复制
default diagnostic handler only filters for errors	默认诊断处理程序仅过滤错误
refactor instruction scheduling hints	重构指令调度提示
renamed instruction scheduling variants	重命名指令调度变体
added documentation regarding current variants	增加了有关当前变体的文档
enable mixed precision matmul test	启用混合精度矩阵测试
this commit enables mixed precision matmul test for amd backend	此提交允许对AMD后端进行混合精度矩阵测试
this leads to a segfault (which can be reproed on the base rev with the lit test added in this pr)	这会导致段错误（可通过本PR中添加的lit测试在基础版本上复现）
p.s. the lit test added in this pr is not exactly minimal	附言：本PR中添加的lit并不完全是最小测试
fix argument passing for internal parameters in function declarations	修复函数声明中内部参数的参数传递问题
use reference instead of copies in few places	在少数地方使用引用而不是副本
apply fixes suggested by coverity static analysis	应用覆盖率静态分析建议的修复
add missing precondition in optimize acc init	在优化acc-init中添加缺少的先决条件
we need scalar select to be able to do this optimization	我们需要标量选择才能进行此优化
fix accumulator init optimization for integer matmuls	修复整数matmul的累加器初始化优化问题
define an extract slice operation	定义提取切片操作
it enables breaking down large tiles of tensors into smaller ones for better instruction interleaving and scheduling	该功能支持将大型张量分块（Tiling）分解为更小的单元，以实现更优的指令交错（Interleaving）和调度优化（Scheduling）
this can be useful for hiding global memory latency when a global load/store can be efficiently split into several loads/stores to be overlapped with compute for attention	这一技术能有效隐藏全局内存访问延迟——当全局加载/存储操作可被高效拆分为多次独立的内存访问时，即可与注意力机制的计算过程重叠执行
add a comment	添加评论
new comment	新评论
markdown input: edit mode selected	Markdown输入：已选择编辑模式
unordered list	无序列表
numbered list	数字列表
task list	任务列表
saved replies	已保存的回复
slash commands	斜杠命令
use markdown to format your comment	使用Markdown格式化您的评论
add files	添加文件
close issue	关闭问题
more options	更多选项
remember, contributions to this repository should follow its contributing guidelines	请记住，对该存储库的贡献应遵循其贡献指南
no labels	没有标签
no type	没有类型
no projects	没有项目
no milestone	没有里程碑
none yet	暂无
code with copilot agent mode	使用Copilot Agent模式编写代码
select code repository	选择代码存储库
no branches or pull requests	无分支或拉取请求
you're not receiving notifications from this thread	您没有收到来自该主题的通知
issue actions	问题操作
describe the bug	描述错误
environment details	环境详细信息
open edits	开放编辑
couldn't load	无法加载
try again	再试一次
looks like something went wrong	看起来出了问题
comment actions for comment	评论的评论操作
no one assigned	没有人分配
browse files	浏览文件
support online build on windows	支持在Windows上的在线构建
expand file tree	展开文件树
search within code	在代码中搜索
open diff view settings	打开Diff视图设置
customizable line height	可自定义的行高
the default line height has been increased for improved accessibility	默认行高已增加，以提高可访问性
you can choose to enable a more compact line height from the view settings menu	您可以从视图设置菜单中选择启用更紧凑的行高
enable compact line height	启用紧凑的行高
copy file name to clipboard	将文件名复制到剪贴板
expand all lines	展开所有行
original file line number	原始文件行号
diff line number	Diff行号
diff line change	Diff行更改
already up to date	已经更新
fork of the triton language and compiler for windows support and easy installation	Triton语言和编译器的分支，支持Windows，并且易于使用
mit license	MIT许可证
triton fork for windows support	支持Windows的Triton分支
the main-windows branch is unstable and may be force pushed	main-windows分支不稳定，可能会被强制推送
thank you all	谢谢大家
free software should run on non-free platforms, as per richard stallma	按照Richard Stallma的说法，自由软件应该在非自由平台上运行
this is required by torch.compile, and torchao, sageattention, unsloth, and more packages	这是torch.compile、torchao、SageAttention、Uncloth等软件包所必需的
memory/disk swap on wsl is hard	WSL上的内存/磁盘交换很困难
triton.jit and torch.compile just work	triton.jit和torch.compile刚刚开始
all unit tests passed (thanks comfy org for generously providing the ci runners!)	所有单元测试均已通过（感谢Comfy Org慷慨提供CI运行器！）
when i run flux or hunyuanvideo in comfyui on windows, it's almost as fast as on wsl on the same machine	当我在Windows上的ComfyUI中运行Flux或HunyuanVideo时，它几乎和在同一台机器上的WSL上一样快
windows 10 and 11 are supported	支持Windows10和11
only nvidia gpu is supported, help wanted to support other backends	仅支持Nvidia GPU，希望帮助支持其他后端
triton accelerates your ai model by compiling things on your computer	Triton通过在您的计算机上编译东西来加速您的AI模型
you need to install it in the correct environment	您需要在正确的环境中安装它
check your gpu model	检查GPU型号
technically they're categorized by 'compute capability' (also known as 'cuda arch' or 'sm'), and here i use rtx models for example	从技术上讲，它们按“计算能力”（也称为“CUDA arch”或“sm”）分类，这里我使用RTX型号作为示例
python environment	Python环境
check how your python is installed	检查您的Python安装的如何
either of the following environments is supported	支持以下任一环境
embeded: you use an all-in-one package of comfyui (or some other ai software)	嵌入式：您使用ComfyUI（或其他一些AI软件）的一体化软件包
other ai software may put this folder at a different path	其他AI软件可能会将此文件夹放在其他路径上
in this case, don't directly run python, but use the full path	在这种情况下，不要直接运行Python，而要使用完整的路径
also, don't directly run pip, but instead run	另外，不要直接运行pip，而是运行
conda: you create a virtual environment using conda	Conda：您使用Conda创建虚拟环境
python venv: you create a virtual environment using venv or virtualenv	Python venv：使用venv或virtualenv创建虚拟环境
for other environment managers like poetry or uv, if you find problems, please open an issue	对于其他环境管理器，如Poetry或uv，如果你发现有困难，请打开一个问题
make sure what environment you're using	确定你使用的是什么环境
if you see multiple python installations, make sure that you install and run everything from the first one	如果你看到多个Python安装，请确保从第一个开始安装并运行所有内容
if you're using comfyui with embeded python, then don't use conda or venv	如果您将ComfyUI与嵌入式Python一起使用，请不要使用Conda或venv
if you're already using conda, then always create a new env using conda, and don't use python venv	如果您已经在使用Conda，请始终使用Conda创建一个新的Env，并且不要使用Python venv
although technically triton can be used alone, in the following let's assume you use it with pytorch	尽管从技术上可以单独使用Triton，但在下面，让我们假设您将其与PyTorch一起使用
check your pytorch version	检查你的PyTorch版本
pytorch 2.3 and older are not supported	PyTorch2.3及更早版本不受支持
pytorch tagged with cuda 12 is required	标有CUDA12的PyTorch是必需的
cuda 11 is not supported	CUDA11不受支持
since the release triton-windows==3.2.0.post11, a minimal cuda toolchain is bundled in the triton wheels, so you don't need to manually install it	自triton-windows==3.2.0.post11版本发布起，Triton的wheel包中已捆绑最小化的CUDA工具链，因此您无需手动安装它
triton 3.1 and 3.2 bundles cuda 12.4, and triton 3.3 bundles cuda 12.8	Triton3.1和3.2捆绑CUDA12.4，Triton3.3捆绑CUDA12.8
they should be compatible with other cuda 12.x because of the minor version compatibility of cuda	由于CUDA的次要版本兼容性，它们应该与其他CUDA12.x兼容
cuda 11 and older are not supported	CUDA11及更早版本不受支持
if you need to override the cuda toolchain, you can set the environment variable cuda_path	如果需要覆盖CUDA工具链，可以设置环境变量CUDA_PATH
instructions for older or custom wheels without bundled cuda	未捆绑CUDA的旧版本或定制wheel的说明
c compiler	C编译器
since the release triton-windows==3.2.0.post13, tinycc is bundled in the triton wheels, so you don't need to manually install a c compiler to use triton	自发布triton-windows==3.2.0.post13起，TinyCC被捆绑在Triton wheel中，因此您不需要手动安装C编译器来使用Triton
packages that directly call triton.jit, such as sageattention, will just work	直接调用triton.jit的包，如SageAttention，将正常工作
you still need to install a c++ compiler if you use torch.compile targeting cpu	如果你使用针对CPU的torch.compile，你仍然需要安装一个C++编译器
this may happen when you use nodes like 'compilemodel' in comfyui	当您在ComfyUI中使用“CompileModel”等节点时，可能会出现这种情况
triton does not affect how pytorch configures the c++ compiler in this case	在这种情况下，Triton不会影响PyTorch配置C++编译器的方式
the new policy will affect the way we do business	新政策将影响我们做生意的方式
does second hand smoke affect the health of all of us	二手烟会影响我们所有人的健康吗
the patient showed flat affect	患者表现出情感淡漠
the effect of the medication was immediate	药物的效果是立即的
the beneficial effects of exercise are well documented	锻炼的益处是有据可查的
the law will effect changes in the tax system	法律将使税收系统发生变化
if you need to override the c compiler, you can set the environment variable cc	如果需要覆盖C编译器，可以设置环境变量CC
msvc, gcc, and clang are supported for the jit compilation in triton	Triton中的JIT编译支持MSVC、GCC和Clang
instructions for older or custom wheels without bundled tinycc	不带捆绑TinyCC的旧版本或定制wheel的说明
note on automatically adding the path	关于自动添加路径的说明
if you've installed an old version of triton, first uninstall it	如果您安装了旧版本的Triton，请先卸载它
now you can install triton-windows 3.3, or upgrade the already installed version	现在，您可以安装triton-windows3.3，或升级已安装的版本
to prevent breaking with your installed pytorch when a new version of triton is released in future, you can limit the version to be < 3.4	为避免未来Triton新版本发布时与已安装的PyTorch产生兼容性问题，您可将Triton版本限制在3.4以下
note again that if you're using the embeded python, then instead of directly run pip, you need	再次注意，如果您使用的是嵌入式Python，那么您不需要直接运行pip，而是需要
for triton 3.2, you need	对于Triton3.2，您需要
special notes for comfyui with embeded python	ComfyUI与嵌入式Python的特别说明
there should be a python folder	应该有一个Python文件夹
other ai software may put the python folder at a different path	其他AI软件可能会将Python文件夹放在不同的路径上
if you created a venv, depending on how you created it, the python folder may be the venv folder or the venv\scripts\ folder	如果你创建了一个venv，根据你创建它的方式，Python文件夹可能是venv文件夹或venv\Scripts\文件夹
you need to put two folders include and libs into the python folder to make triton work	您需要将两个文件夹include和libs放入Python文件夹中，才能使Triton工作
be careful: it is 'libs', not 'lib'	小心：这是“libs”，不是“lib”
there may already be a folder lib in the python folder, containing things like site-packages or __future__.py	Python文件夹中可能已经有一个文件夹Lib，其中包含站点包或__future__.py等内容
if you're using framepack with python 3.10, then download the two folders here	若您正在Python3.10环境下使用FramePack，请在此处下载这两个文件夹
the minor version (3.9/3.10 ...) must be correct, but the patch version (3.10.6/3.10.7 ...) can be different	次要版本（3.9/3.10 ...）必须正确，但是补丁版本（3.10.6/3.10.7 ...）可能是不同的
test if it works	测试是否工作
before using triton in larger projects like comfyui, please run the following script to test if triton itself works	在ComfyUI等大型项目中使用Triton之前，请运行以下脚本来测试Triton本身是否正常工作
when you open an issue, please show the command you use to run this test, and the full error log	提交问题时，请提供您运行测试所使用的命令及完整的错误日志
troubleshoot the test above	对上述测试进行故障排除
no module named 'triton.language'; 'triton' is not a package	没有名为“triton.language”的模块；“triton”不是一个包
don't name the test script triton.py	不要将测试脚本命名为triton.py
also, check if there is a folder named triton in your current directory	此外，请检查当前目录中是否有名为triton的文件夹
if so, python will think it's the 'triton' package and fail to import	如果是这样，Python会认为它是“triton”包，从而无法导入
module 'pkgutil' has no attribute 'impimporter'	模块'pkgutil'没有属性'ImpImporter'
did you mean: 'zipimporter'	你是说：“zipimporter”吗
this is because your setuptools is outdated	这是因为您的setuptools已经过时
run the following and try again	运行以下命令，然后重试
access is denied	访问被拒绝
this is because of the permission settings of your user folder	这是因为您的用户文件夹的权限设置
dll load failed while importing libtriton	导入libtriton时DLL加载失败
this is usually because your vcredist dlls are too old	这通常是因为你的vcredist DLL太旧了
if you're using conda, then you may try	如果你正在使用Conda，那么你可以试试
if you're not using conda, then you need to find the vcredist dlls (vcruntime140.dll, vcruntime140_1.dll) in your python installation folder	如果你没有使用Conda，那么你需要在Python安装文件夹中找到vcredist DLL（vcruntime140.dll，vcruntime140_1.dll）
embeded python (you use an all-in-one package of comfyui or some other ai software)	嵌入式Python（您可以使用ComfyUI或其他一些AI软件的一体化包）
other python installation (system-wide/user-wide/venv)	其他Python安装（系统范围/用户范围/venv）
after finding the dlls in the python installation folder, you can install the latest vcredist, then copy the dlls msvcp140.dll, vcruntime140.dll, vcruntime140_1.dll from c:\windows\system32\ to the python installation folder, and replace the existing ones	在Python安装文件夹中找到DLL后，您可以安装最新的vcredist，然后将dll msvcp140.dll、vcruntime140.dll、vcruntime140_1.dll从C:\Windows\System32\复制到Python安装文件夹，并替换现有的DLL
you can right-click the dll -> properties -> details to see its version	您可以右键单击DLL->属性->详细信息以查看其版本
a new enough version, such as 14.42, is required by my triton wheels	我的Triton wheel需要一个足够的新版本，例如14.42
dll load failed while importing cuda_utils	导入cuda_utils时DLL加载失败
delete the cache folders	删除缓存文件夹
you may also need to delete these cache folders when you change the python version, install another version of triton, or change the c compiler or cuda	当您更改Python版本、安装其他版本的Triton或更改C编译器或CUDA时，可能还需要删除这些缓存文件夹
it's ok if these folders do not exist on your computer	如果您的计算机上不存在这些文件夹，也没关系
the first folder exists only if you have used triton.jit (which is used by packages like sageattention), and the second folder exists only if you have used torch.compile	第一个文件夹仅在您使用triton.jit（由SageAttention等包使用）时存在，第二个文件夹仅在您使用torch.compile时存在
double check your python version: you can run get-command -all python in powershell (or where python in cmd) to see the installation path of python, and python --version to see its version	请仔细检查您的Python版本：在PowerShell中可运行Get-Command -All python（或在CMD中运行where python）查看Python安装路径，运行python --version查看其版本号
if you're using comfyui with embeded python, make sure that you copy-pasted the folders include and libs from the correct version of python	如果您将ComfyUI与嵌入式Python一起使用，请确保从正确版本的Python复制粘贴文件夹include和libs
you also need to delete the cache folders above	您还需要删除上面的缓存文件夹
if the above still doesn't work, you may try	如果上述方法仍然无效，您可以尝试
install dlltracer in the same python environment	在同一Python环境中安装dlltracer
in an administrator powershell, run the following script	在管理员PowerShell中，运行以下脚本
open an issue	打开一个问题
security reminder: you don't need the administrator privilege to run triton and other usual python code	安全提示：运行Triton和其他常见的Python代码不需要管理员权限
it's only dlltracer that needs it	只有dlltracer需要它
if it shows failed \device\...\cuda_utils.pyd, please also	如果显示失败\Device\...\cuda_utils.pyd，也请
find cuda_utils.pyd at this location	在此位置找到cuda_utils.pyd
use dependenciesgui (or similar tools) to check what dlls this cuda_utils.pyd depends on, and send a screenshot (or other related information) in the issue	使用DepentenciesGui（或类似工具）检查此cuda_utils.pyd依赖于哪些DLL，并在问题中发送屏幕截图（或其他相关信息）
known issues	已知问题
windows file path length limit (260) causes compilation failure	Windows文件路径长度限制（260）导致编译失败
torch.compile may create temp files with very long filenames, causing errors like	torch.compile可能创建具有很长的文件名的临时文件，从而导致错误
or errors like	或如错误
the filename or extension is too long	文件名或扩展太长
the solution is to enable windows' long path support	解决方案是启用Windows的长路径支持
a reboot is required after the modification	修改后需要重启
fp8 is not supported on rtx 30xx and older gpus	RTX30xx及更早版本的GPU不支持fp8
if you see errors like	如果您看到类似的错误
and in the full error log you find	然后在完整的错误日志中您可以找到
fp8e4nv data type is not supported on cuda arch < 89	CUDA arch<89不支持fp8e4nv数据类型
then it's because in triton, fp8 only works on nvidia gpus with sm >= 89, such as rtx 40xx and newer	那么这是因为在Triton中，fp8仅适用于sm>=89的Nvidia GPU，如RTX40xx及更高版本
you may disable fp8 in the node or the code	您可以在节点或代码中禁用fp8
this is not windows-specific	这不是特定于Windows平台的
help wanted if anyone has time for this	诚邀有时间者协助
error with os.rename	os.rename的错误
cannot create a file when that file already exists	当该文件已经存在时，无法创建文件
then you need	那么你需要
this has been fixed since pytorch 2.6	自PyTorch2.6起，这个问题已经修复
error with model offloading	模型卸载错误
if you're using comfyui, the model is compiled, and you see error messages like	如果您使用的是ComfyUI，则模型会被编译，您会看到类似的错误消息
pointer argument (at 0) cannot be accessed from triton (cpu tensor?)	无法从Triton（CPU张量？）访问指针参数（在0处）
then you may use --gpu-only when launching comfyui to disable model offloading	然后，您可以仅在启动ComfyUI时使用--gpu-only来禁用模型卸载
no module named 'triton.ops'	没有名为“triton.ops”的模块
triton.ops was removed in triton 3.1, and this is because some of your python package is outdated (most likely bitsandbytes)	Triton3.1中删除了triton.ops，这是因为您的一些Python包已经过时（最有可能是bitsandbytes）
this is for developers	这是为开发人员准备的
an implementation of regexes, supporting a relatively rich set of features, including backreferences and look-around	正则表达式的一种实现，支持相对丰富的功能集，包括回溯引用和环视断言
python bindings for symphonia/opus - read various audio formats from python and write opus files	symphonia/opus的Python绑定——从Python读取多种音频格式并写入opus文件
python bindings for the symphonia and opus crates	symphonia和opus库的Python绑定
easily load various audio file formats into numpy arrays	轻松地将各种音频文件格式加载到Numpy数组中
read/write ogg/opus audio files with streaming support	支持流式读取/写入Ogg/Opus音频文件
the python wheels are available on pypi	Python wheel可在PYPI上找到
if you're seeing an issue with cmake saying "compatibility with cmake < 3.5 has been removed from cmake.", this is because building opus is not compatible with cmake 4.x	如果您看到CMake的问题说“与CMake<3.5的兼容性已从CMake中删除。”这是因为构建Opus与CMake4.x不兼容
install a 3.x version (e.g. 3.31) and then set the cmake environment variable to use it, e.g.	安装3.x版本（例如3.31），然后设置CMAKE环境变量以使用它，例如
or use your system's package manager	或使用系统的软件包管理器
download some sample audio file	下载一些示例音频文件
read an audio file	读取一个音频文件
save as wav	保存为wav
could you pass me the salt, please	请把盐递给我好吗
i'll call you back later	我稍后回电给你
the algorithm improves computational efficiency by 40%	该算法将计算效率提高了40%
quantum entanglement challenges classical physics	量子纠缠现象挑战了经典物理学
data encryption ensures information security	数据加密技术保障信息安全
the summit addressed climate change mitigation	峰会讨论了气候变化缓解措施
global trade volumes declined by 2.3% this quarter	本季度全球贸易量下降2.3%
the autumn leaves danced like golden flames in the wind	秋叶如金色火焰般在风中起舞
had i known the truth, i would have acted differently	早知道真相，我就会采取不同行动
the contract shall be governed by the laws of china	本合同受中国法律管辖
symptoms typically manifest within 24 hours	症状通常在24小时内显现
critical thinking enhances problem-solving skills	批判性思维能提升问题解决能力
use a tanh activation in the xlm-roberta classification head	在XLM-RoBERTa模型的分类头中使用tanh激活函数
last month	上个月
files changed	文件更改
show options	显示选项
sorry for making the commit on this day, but i'm really, really not fooling	很抱歉在这一天做出提交，但我真的不是在开玩笑
however, this is not thoroughly tested by myself, i can't guarantee that it's free of bugs	然而，这并没有经过我自己的彻底测试，我不能保证它没有错误
the --classpath option(s) of d8 doesn't act like that of javac: the :/; separator is likely to cause problems here	d8工具的--classpath选项与javac行为不同，使用:或;分隔符可能导致问题
the multidex format may cause problem on old android versions (loading it using dexclassloader instead of inmemorydexclassloader introduced in api 26), even if there is only one classes.dex output file	即使只有一个classes.dex输出文件，Multidex格式在旧版Android上也可能会导致问题（使用DexClassLoader而不是API26中引入的InMemoryDexClassLoader进行加载）
specifying --min-api 20 solves this problem	指定--min-api 20解决了这个问题
newer jdk versions (including jdk 21 and above) may not work with android d8 if there are anonymous classes in the java code, which produces files like cls$1.class	如果Java代码中存在匿名类，则较新的JDK版本（包括JDK21及更高版本）可能无法与Android D8兼容，从而产生类似Cls$1.class的文件
this is fixed in build tools 35.0.0	在构建工具35.0.0中已经修复此问题
i'm not sure if it's good to add this warning here	我不确定在此处添加此警告是否合适
i'm not printing cargo:rerun-if-changed=path for all input files used in javabuild and dexer	我没有为JavaBuild和Dexer使用的所有输入文件打印cargo:rerun-if-changed=PATH指令
i just used it for env variables being used inside this crate	我只是用它来表示这个库内使用的环境变量
i thought the user can do so for their source files (if required)	我认为用户可以为其源代码文件这样做（如果需要）
feel free to change this behavior, though	不过，请随时改变这种行为
add or remove reactions	添加或移除反应
view reviewed changes	查看审查的更改
thanks very much	非常感谢
great work on the documentation, it's very nice	文档做得很好，非常细致
can you add the "notes" that you posted in the pr description as doc comments on the dexer type such that future users of said type will be made aware of those caveats	您能否将您在PR描述中发布的“注释”添加为Dexer类型的文档注释，以便该类型的未来用户了解这些注意事项
fix dexer docs	修复Dexer文档
i've made these requested changes	我已经做了这些要求的更改
--lib and --classpath options are probably redundant under --no-desugaring, but they don't cause any problem under my test case	--lib和--classpath选项在--no-desugaring下可能是多余的，但它们在我的测试用例下不会引起任何问题
thanks, much appreciated	谢谢，非常感谢
i'll release the crate to crates.io shortly	我会很快把库发布到crates.io
published v0.1.2 to crates.io	已发布V0.1.2到crates.io
thanks again	再次感谢
merge info	合并信息
pull request successfully merged and closed	拉取请求已成功合并并关闭
you're all set — the branch has been merged	一切就绪，分支已合并
add .patch or .diff to the end of urls for git’s plaintext views	在Git纯文本视图的URL末尾添加.patch或.diff
successfully merging this pull request may close these issues	成功合并此拉取请求可能会关闭这些问题
audiocraft is a library for audio processing and generation with deep learning	Audiocraft是一个用于深度学习音频处理和生成的库
it features the state-of-the-art encodec audio compressor / tokenizer, along with musicgen, a simple and controllable music generation lm with textual and melodic conditioning	它具有最先进的EnCodec音频压缩器/标记器，以及MusicGen，一个简单可控的音乐生成LM，具有文本和旋律调节功能
custom properties	自定义属性
audiocraft is a pytorch library for deep learning research on audio generation	AudioCraft是一个PyTorch库，用于音频生成的深度学习研究
audiocraft contains inference and training code for two state-of-the-art ai generative models producing high-quality audio: audiogen and musicgen	AudioCraft包含两个最先进的AI生成模型的推理和训练代码，这两个模型可以产生高质量的音频：AudioGen和MusicGen
audiocraft requires python 3.9, pytorch 2.1.0	AudioCraft需要Python3.9，PyTorch2.1.0
to install audiocraft, you can run the following	要安装AudioCraft，您可以运行以下命令
best to make sure you have torch installed first, in particular before installing xformers	最好确保先安装torch，特别是在安装xformers之前
you might need the following before trying to install the packages	在尝试安装软件包之前，您可能需要以下内容
then proceed to one of the following	然后进行以下操作之一
bleeding edge	最前沿
we also recommend having installed, either through your system or anaconda:ffmpeg	我们还建议通过您的系统或Anaconda安装：FFMPEG
or if you are using anaconda or miniconda	或者如果您使用的是Anaconda或Minconda
at the moment, audiocraft contains the training code and inference code for	目前，AudioCraft包含以下训练代码和推理代码
musicgen: a state-of-the-art controllable text-to-music model	MusicGen：最先进的可控文本到音乐模型
audiogen: a state-of-the-art text-to-sound model	AudioGen：最先进的文本转声音模型
encodec: a state-of-the-art high fidelity neural audio codec	EnCodec：最先进的高保真神经音频编解码器
multi band diffusion: an encodec compatible decoder using diffusion	多频带扩散模型：基于扩散算法的EnCodec兼容解码器
magnet: a state-of-the-art non-autoregressive model for text-to-music and text-to-sound	MAGNeT：一种最先进的文本到音乐和文本到声音的非自回归模型
audioseal: a state-of-the-art audio watermarking	AudioSeal：一种最先进的音频水印技术
musicgen style: a state-of-the-art text-and-style-to-music model	MusicGen风格：最先进的文本和风格到音乐模型
jasco: "high quality text-to-music model conditioned on chords, melodies and drum tracks"	JASCO：“基于和弦、旋律与鼓轨的高质量文本生成音乐模型”
training code	训练代码
audiocraft contains pytorch components for deep learning research in audio and training pipelines for the developed models	AudioCraft包含用于音频深度学习研究的PyTorch组件及已开发模型的训练流水线
for a general introduction of audiocraft design principles and instructions to develop your own training pipeline, refer to the audiocraft training documentation	如需获取AudioCraft设计原则的全面介绍以及开发自定义训练流水线的指导说明，请参阅AudioCraft训练文档
for reproducing existing work and using the developed training pipelines, refer to the instructions for each specific model that provides pointers to configuration, example grids and model/task-specific information and faq	如需复现现有成果并使用已开发的训练流水线，请参阅各具体模型的说明文档，其中包含配置指引、示例配置网格、模型/任务特定信息及常见问题解答
api documentation	API文档
we provide some api documentation for audiocraft	我们为AudioCraft提供了一些API文档
is the training code available	训练代码是否可用
yes! we provide the training code for encodec, musicgen,multi band diffusion and jasco	是的！我们为EnCodec、MusicGen、多频带扩散和JASCO提供训练代码
where are the models stored	模型存放在哪里
hugging face stored the model in a specific location, which can be overridden by setting the environment variable for the audiocraft models	Hugging Face将模型存储在特定位置，可以通过为AudioCraft模型设置环境变量来覆盖该位置
in order to change the cache location of the other hugging face models, please check out the hugging face transformers documentation for the cache setup	如需修改其他Hugging Face模型的缓存路径，请查阅Hugging Face Transformers文档中的缓存设置说明
finally, if you use a model that relies on demucs (e.g. musicgen-melody) and want to change the download location for demucs, refer to the torch hub documentation	最后，如果您使用依赖于Demucs的模型（例如musicgen-melody）并想要更改Demucs的下载位置，请参阅Torch Hub文档
the code in this repository is released under the mit license as found in the license file	此存储库中的代码根据LICENSE文件中的MIT许可证发布
the models weights in this repository are released under the cc-by-nc 4.0 license as found in the license_weights file	此存储库中的模型权重根据LICENSE_weights文件中的CC-BY-NC 4.0许可证发布
for the general framework of audiocraft, please cite the following	对于Audiocraft的一般框架，请引用以下内容
when referring to a specific model, please cite as mentioned in the model specific readme, e.g ./docs/musicgen.md, ./docs/audiogen.md, etc	引用特定模型时，请按照该模型专属README文档中的说明进行标注，例如参考./docs/MUSICGEN.md、./docs/AUDIOGEN.md等文件中的指引
compression models or wrapper around existing models	压缩模型或围绕现有模型的包装
in particular, provides the implementation for mimi	特别是为Mimi提供了实现
also defines the main interface that a model must follow to be usable as an audio tokenizer	还定义了模型必须遵循的主要接口，以便可用作音频标记器
tencent cloud codebuddy (hereinafter referred to as codebuddy) is a self-developed development and programming efficiency-enhancing tool by tencent cloud	腾讯云CodeBuddy（以下简称CodeBuddy）是腾讯云自主研发的开发和编程效率提升工具
driven by the dual-model framework of tencent hunyuan and deepseek, it is designed to be developer-friendly, easy to use, and practical	由腾讯混元和DeepSeek双模型框架驱动，注重开发者友好性、易用性和实用性
codebuddy provides developers with ai-powered technical q&a, the craft software coding intelligent agent, intelligent code completion, unit testing, intelligent code review, code repair, and other agent-based extended capabilities	CodeBuddy为开发者提供AI驱动的技术问答、Craft软件编码智能代理、智能代码补全、单元测试、智能代码审查、代码修复以及其他基于代理的扩展能力
it is compatible with the mcp open ecosystem and supports team knowledge base management, custom intelligent agents and command management, multi-model integration, and enterprise account integration	它与MCP开放生态系统兼容，支持团队知识库管理、自定义智能代理和命令管理、多模型集成和企业帐户集成
codebuddy assists developers in improving coding efficiency and quality, helping r&d teams enhance productivity and effectiveness	CodeBuddy帮助开发人员提高编码效率和质量，帮助研发团队提高生产力和效率
note: product features are continuously updated, and some ides may experience delays due to version release schedules	注意：产品功能会不断更新，一些IDE可能会因版本发布时间表而出现延迟
ai-powered tech chat: intelligent ai-driven conversations to effortlessly tackle complex technical challenges	AI技术聊天：智能AI驱动的对话，轻松应对复杂的技术挑战
supports flexible configuration and switching between multiple models, including third-party deepseek model integration	支持灵活配置和切换多种模型，并支持第三方DeepSeek模型接入
integrated ide tech chat: supports one-click insertion of code from conversations directly into the compilation area for rapid q&a	集成IDE技术聊天：支持一键将对话中的代码直接插入编译区域，以便快速问答
code completion: smart suggestions to efficiently complete your programming tasks	代码完成：智能建议，高效完成您的编程任务
release notes	发行说明
user agreement	用户协议
review now	立即查看
remind me later	稍后提醒我
open search	打开搜索
open main menu	打开主菜单
free for non-commercial use	非商业用途免费
a powerhouse ide for rust developers	Rust开发人员的强大IDE
request a demo	请求演示
rustrover goes ai	RustRover走向人工智能
less routine, more coding joy	减少无聊，增添编码乐趣
all refined jetbrains ai tools – right in your ide, for free	所有精炼的JetBrains AI工具–直接在您的IDE中免费使用
coding agent	代码智能体
unlimited code completion	无限的代码完成
offline mode	离线模式
latest ai models	最新的AI模型
codebase context	代码库上下文
multi-file edits	多文件编辑
vcs assistance	VCS协助
discover more	发现更多
focus on what matters while	专注于重要的事情
rustrover handles the rest	剩下的交给RustRover处理
code faster	编码速度更快
save time	节省时间
explore codebase	探索代码库
run, debug, test	运行、调试、测试
manage projects	管理项目
previous item	上一个项目
next item	下一个项目
write your code faster	更快地编写代码
benefit from context-aware code completion and generation, on-the-fly analysis and quick-fixes, smart refactorings, live templates, and more	受益于上下文感知代码完成和生成、即时分析和快速修复、智能重构、实时模板等
develop applications for the web	开发Web应用程序
rustrover provides seamless integration with frontend development workflows	RustRover提供与前端开发工作流程的无缝集成
issue requests and analyze responses with the built-in http client	使用内置的HTTP客户端发出请求并分析响应
use the docker tool to manage various project components and explore your database schemas and tables with the database tooling	使用Docker工具管理各种项目组件，并使用数据库工具探索数据库模式和表
work in a team efficiently	高效团队合作
rustrover comes with all the teamwork tools you need	RustRover带有您需要的所有团队合作工具
code together in real time and talk to others right from the ide	实时一起编写代码，并直接从IDE与他人交谈
share your project configuration, including the code style settings	共享您的项目配置，包括代码样式设置
work smoothly with git, github, and gitlab, exploring commits and pull requests, creating branches, and reviewing code	与Git、GitHub和GitLab顺畅协作，探索提交和拉取请求，创建分支，审查代码
ready to use out of the box	开箱即用
start coding immediately without the hassle of installing and configuring numerous plugins	立即开始编码，无需安装和配置大量插件
rustrover provides a comprehensive development environment with seamless integration of rust, cargo, and cargo.toml	RustRover提供了一个全面的开发环境，实现了Rust、Cargo和Cargo.toml的无缝集成
it includes features like remote support, database management, git integration, and more	它包括远程支持、数据库管理、Git集成等功能
web technologies from webstorm and database tools from datagrip are also available	WebStorm的Web技术和DataGrip的数据库工具也可用
explore documentation	浏览文档
recommended by rust community members	Rust社区成员推荐
charlie marsh	查理·马什
founder of astral, creator of ruff and uv	Ruff和UV的创建者Astral的创始人
rustrover has been my ide of choice since the early access releases	自Early Access发布以来，RustRover一直是我选择的IDE
and now it powers all of my development time across ruff, uv, and other large-scale rust projects	现在，它为我在Ruff、UV和其他大型Rust项目上的所有开发时间提供了动力
with rustrover, i can perform complex refactors spanning hundreds of thousands of lines of code, navigate across complex dependency trees, and, ultimately, write rust with confidence	有了RustRover，我可以执行跨越数十万行代码的复杂重构，在复杂的依赖树中导航，并最终自信地编写Rust
all you’ll ever need for rust development	Rust开发所需的一切
try for free	免费试用
if you use rustrover for non-commercial purposes, meaning you do not receive any direct financial compensation for the work you do with it, you can use the ide for free	如果您将RustRover用于非商业用途，即您不会因使用该软件的工作获得任何直接经济补偿，则可以免费使用该集成开发环境(IDE)
content creation	内容创建
you can use rustrover in your videos or content for educational purposes, like tutorials or demonstrations, even if you charge to access that content	您可以在视频或内容中使用RustRover进行教育，如教程或演示，即使您对访问该内容收费
this means that you can use the product in your teaching materials or online courses without worrying about licensing restrictions	这意味着您可以在教材或在线课程中使用该产品，而无需担心许可限制
check out the jetbrains content creators program to discover more options	查看JetBrains内容创作者计划，了解更多选项
hobbies and learning	爱好和学习
according to stack overflow↗, 68% of developers code outside of work as a hobby, and nearly 40% do so for professional growth or self-paced learning	根据Stack Overflow↗的调查，68%的开发人员将工作之余编写代码作为一种爱好，近40%的开发人员这样做是为了职业发展或自主学习
enjoy free time coding in rust and develop your project with rustrover	享受免费Rust编程，通过RustRover开发您的项目
open-source project development	开源项目开发
rust is known for its strong open-source community	Rust以其强大的开源社区而闻名
enhance your project with rustrover and contribute to the thriving rust ecosystem	使用RustRover增强您的项目，为繁荣的Rust生态系统做出贡献
explore more about jetbrains support for open-source projects	探索更多有关JetBrains对开源项目的支持
what qualifies as non-commercial use	什么才算非商业用途
which license should i choose if i want to use rustrover for both non-commercial and commercial projects	如果我想将RustRover用于非商业和商业项目，我应该选择哪个许可证
what features are included under the free license	免费许可证包含哪些功能
how does a free trial work	免费试用是如何运作的
does my ide send any data to jetbrains	我的IDE是否向JetBrains发送任何数据
can i use rustrover when my paid subscription is over	付费订阅结束后，我可以使用RustRover吗
still not sure if rustrover is right for you	仍然不确定RustRover是否适合您
contact us and we will answer any questions you may have	联系我们，我们将回答您的任何问题
subscribe to rustrover news	订阅RustRover新闻
i agree that my personal data will be processed for this purpose	我同意为此目的处理我的个人数据
follow us	关注我们
rustrover blog	RustRover博客
bug and issue tracker	Bug和问题跟踪器
team tools	团队工具
all products	所有产品
c++ tools	C++工具
data tools	数据工具
game development	游戏开发
tools for business	商业工具
jetbrains research	JetBrains研究
open source projects	开源项目
academic licensing	学术许可
open source partnerships	开源合作伙伴关系
user groups	用户组
developer recognition	开发者表彰
content creators	内容创作者
sales support	销售支持
product support	产品支持
licensing faq	许可常见问题
events and livestreams	活动和直播
industry reports	行业报告
desktop art	桌面艺术
our commitment	我们的承诺
brand assets	品牌资产
partners and resellers	合作伙伴和经销商
merchandise store	商品店
trust center	信任中心
jetbrains on facebook	Facebook上的JetBrains
jetbrains on x (formerly twitter)	X上的JetBrains（以前称为Twitter）
jetbrains on linkedin	LinkedIn上的JetBrains
jetbrains on youtube	YouTube上的JetBrains
jetbrains on instagram	Instagram上的JetBrains
jetbrains on tiktok	TikTok上的JetBrains
jetbrains blog	JetBrains博客
jetbrains rss feed	JetBrains的RSS源
jetbrains merchandise store	JetBrains商品店
china mainland	中国大陆
privacy & security	隐私与安全
terms of use	使用条款
genuine tools	正版工具
developed with drive and intellij idea	用热忱与IntelliJ IDEA打造
thank you for downloading rustrover	感谢您下载RustRover
we'd love to learn about your goals with rustrover - take a quick survey to share your thoughts	我们很想通过RustRover了解您的目标——进行快速调查以分享您的想法
your download should start shortly	您的下载应该很快开始
if it doesn't, please use the direct link	如果没有，请使用直链
download and verify the file sha-256 checksum	下载并验证文件SHA-256校验和
learn more about the digital signatures of jetbrains binaries	了解有关JetBrains二进制文件的数字签名的更多信息
browse the documentation↗ to get an overview of rustrover, learn how to navigate inside the ide, and find out what features are available in the product	浏览文档↗获取RustRover的概述，了解如何在IDE内部导航，并找出产品中可用的功能
let’s stay in touch	让我们保持联系
enter your email to receive occasional news related to rustrover	输入您的电子邮件以接收与RustRover有关的偶尔新闻
remote development	远程开发
the ultimate coding experience for a remote world	远程世界的终极编码体验
get access to your remote environments right from your jetbrains ide	直接从JetBrains IDE访问远程环境
learn more	了解更多
the ide for professional development in java and kotlin	Java和Kotlin的专业开发IDE
the only python ide you need	你唯一需要的Python IDE
powerful continuous integration out of the box	开箱即用的强大持续集成
powerful project management for all your teams	为您的所有团队提供强大的项目管理
adding script for making voice conditionings	添加用于制作语音条件的脚本
the sun rises in the east	太阳从东方升起
she enjoys reading novels in her free time	她闲暇时喜欢读小说
artificial intelligence is transforming many industries	人工智能正在改变许多行业
they decided to postpone the meeting until next week	他们决定将会议推迟到下周
this restaurant serves authentic italian cuisine	这家餐厅提供正宗的意大利菜
the researchers published their findings in a scientific journal	研究人员在科学期刊上发表了他们的发现
he apologized for arriving late to the appointment	他为约会迟到而道歉
the government announced new policies to boost the economy	政府宣布了提振经济的新政策
children should learn to respect cultural differences	孩子们应该学会尊重文化差异
the software update improved the system's performance significantly	软件更新显著提高了系统性能
opus is a codec for interactive speech and audio transmission over the internet	Opus是一种用于通过互联网进行交互式语音和音频传输的编解码器
opus can handle a wide range of interactive audio applications, including voice over ip, video conferencing, in-game  chat, and even remote live music performances	Opus可以处理各种交互式音频应用程序，包括IP的语音，视频会议，游戏中聊天，甚至远程现场音乐表演
it can scale from low bit-rate narrowband speech to very high quality stereo music	它可以从低比特率的窄带语音扩展到非常高质量的立体声音乐
opus, when coupled with an appropriate container format, is also suitable for non-realtime stored-file applications such as music distribution, game soundtracks, portable music players, jukeboxes, and other applications that have historically used high latency formats such as mp3, aac, or vorbis	Opus与适当的容器格式结合使用时，也适用于非实时存储文件应用程序，例如音乐分发、游戏配乐、便携式音乐播放器、点唱机以及其他历史上使用高延迟格式（例如MP3、AAC或Vorbis）的应用程序
opus is specified by ietf rfc 6716	Opus由IETF RFC 6716指定
the opus format and this implementation of it are subject to the royalty-free patent and copyright licenses specified in the file copying	Opus格式及其实现受文件COPYING中规定的免版税专利和版权许可的约束
this package implements a shared library for encoding and decoding raw opus bitstreams	此包实现了一个用于编码和解码原始Opus比特流的共享库
the package also includes a number of test tools used for testing the correct operation of the library	该软件包还包含若干用于测试库正确运行的测试工具
the bitstreams read/written by these tools should not be used for opus file distribution: they include additional debugging data and cannot support seeking	这些工具读写的比特流不应用于Opus文件分发：它们包含额外的调试数据且不支持随机访问
an opus-tools package is available which provides encoding and decoding of ogg encapsulated opus files and includes a number of useful features	opus-tools软件包提供对Ogg封装的Opus文件的编码和解码，并包含许多有用的功能
deep learning and opus	深度学习和Opus
lossy networks continue to be a challenge for real-time communications	有损网络仍然是实时通信的挑战
while the original implementation of opus provides an excellent packet loss concealment mechanism, the team has continued to advance the methodology used to improve audio quality in challenge network environments	虽然Opus的原始实现已具备卓越的丢包隐藏机制，但开发团队仍在持续优化用于提升挑战性网络环境下音频质量的技术方案
in opus 1.5, we added a deep learning based redundancy encoder that enhances audio in lossy networks by embedding one second of recovery data in the padding data of each packet	在Opus1.5中，我们添加了基于深度学习的冗余编码器，通过在每个数据包的填充数据中嵌入一秒的恢复数据来增强有损网络中的音频
the underlying algorithm behind encoding and decoding the recovery data is called the deep redundancy (dred) algorithm	编码和解码恢复数据背后的底层算法称为深度冗余(DRED)算法
by leveraging the padding data within the packet, opus 1.5 is fully backward compatible with prior revisions of opus	通过利用数据包内的填充数据，Opus1.5实现了与旧版本Opus的完全向后兼容
please see the readme under the "dnn" subdirectory to understand dred	请参阅“dnn”子目录下的README以了解DRED
dred was developed by a team that amazon web services initially sponsored, who open-sourced the implementation as well as began the standardization process at the ietf	DRED（深度冗余编码）技术由亚马逊云服务（AWS）最初赞助的团队开发，该团队不仅开源了实现方案，还启动了IETF标准化进程
the license behind opus or the intellectual property position of opus does not change with opus 1.5	Opus所遵循的许可协议及其知识产权状态在1.5版本中保持不变
compiling libopus	编译libopus
to build from a distribution tarball, you only need to do the following	要从发行版tarball构建，您只需要执行以下操作
to build from the git repository, the following steps are necessary	要从Git存储库构建，需要执行以下步骤
set up a development environment	设置开发环境
on an ubuntu or debian family linux distribution	在Ubuntu或Debian家族Linux发行版上
on a fedora/redhat based linux	基于Fedora/Redhat的Linux
or for older redhat/centos linux releases	或者对于较旧的Redhat/Centos Linux版本
on apple macos, install xcode and brew.sh, then in the terminal enter	在Apple macOS上，安装Xcode和brew.sh，然后在终端中输入
clone the repository	克隆存储库
compiling the source	编译源码
on x86, it's a good idea to use a -march= option that allows the use of avx2	在x86上，最好使用-march=选项，允许使用AVX2
install the codec libraries (optional)	安装编解码器库（可选）
once you have compiled the codec, there will be a opus_demo executable in the top directory	一旦编译完编解码器，顶部目录中将有一个opus_demo可执行文件
input and output are little-endian signed 16-bit pcm files or opus bitstreams with simple opus_demo proprietary framing	输入和输出为16位有符号小端序PCM文件，或采用opus_demo简单专有封装格式的Opus比特流
this package includes a collection of automated unit and system tests which should be run after compiling the package especially the first time it is run on a new platform	此包包括一组自动化单元和系统测试，这些测试应在编译包后运行，特别是在首次在新平台上运行时
to run the integrated tests	运行集成测试
there is also collection of standard test vectors which are not included in this package for size reasons but can be obtained from	还有一组标准测试向量，由于尺寸原因，这些向量不包含在本包中，但可以从以下地方获得
compiling libopus for windows and alternative build systems	Windows平台及替代构建系统下的libopus编译
see cmake/readme.md or meson/readme.md	参见cmake/README.md或meson/README.md
portability notes	可移植性说明
this implementation uses floating-point by default but can be compiled to use only fixed-point arithmetic by setting --enable-fixed-point (if using autoconf) or by defining the fixed_point macro (if building manually)	该实现默认使用浮点运算，但可通过两种方式编译为纯定点运算：使用autoconf时设置--enable-fixed-point参数，或手动构建时定义FIXED_POINT宏
the fixed point implementation has somewhat lower audio quality and is slower on platforms with fast fpus, it is normally only used in embedded environments	定点实现的音频质量稍低，在具有快速FPU的平台上速度较慢，通常仅用于嵌入式环境
the implementation can be compiled with either a c89 or a c99 compiler	该实现可以用C89或C99编译器编译
while it does not rely on any _undefined behavior_ as defined by c89 or c99, it relies on common _implementation-defined behavior_ for two's complement architectures	虽然该实现不依赖C89或C99标准定义的任何未定义行为，但需要依赖二进制补码架构中常见的实现定义行为
releases 5	发行版5